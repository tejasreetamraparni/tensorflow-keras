{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "authorship_tag": "ABX9TyMvtsVsjp8yk/4qcwiZ9Oj+"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARdC91GVEySQ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import layers, models\n",
        "from keras import losses, optimizers, metrics\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle"
      ],
      "metadata": {
        "id": "RJKVEKr8NnYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://d17h27t6h515a5.cloudfront.net/topher/2017/February/5898cd6f_traffic-signs-data/traffic-signs-data.zip\"\n",
        "dataset = keras.utils.get_file(\"traffic-signs-data.zip\",\n",
        "                               url,\n",
        "                               extract=True)\n",
        "\n",
        "print(f\"File path:{dataset}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FyoA8OjGfEI",
        "outputId": "b7320858-bce1-4291-bdaf-4db9890bef05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://d17h27t6h515a5.cloudfront.net/topher/2017/February/5898cd6f_traffic-signs-data/traffic-signs-data.zip\n",
            "123524425/123524425 [==============================] - 1s 0us/step\n",
            "File path:/root/.keras/datasets/traffic-signs-data.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_dir = os.path.dirname(dataset)"
      ],
      "metadata": {
        "id": "p-w1elPEOLRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(dataset_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLoANjnJKbFp",
        "outputId": "1fa85a0a-aa73-4d79-8d37-235b9759e3a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['test.p', 'valid.p', 'train.p', 'traffic-signs-data.zip']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pickle.load(open(os.path.join(dataset_dir, \"train.p\"), \"rb\"))\n",
        "val_data = pickle.load(open(os.path.join(dataset_dir, \"valid.p\"), \"rb\"))\n",
        "test_data = pickle.load(open(os.path.join(dataset_dir, \"test.p\"), \"rb\"))"
      ],
      "metadata": {
        "id": "Q0JvZ9NQKuOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTYLaD3qOEzT",
        "outputId": "a1d839fd-00a1-46f5-9a95-a0e12e424201"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['coords', 'labels', 'features', 'sizes'])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_features, train_labels = train_data['features'], train_data['labels']\n",
        "val_features, val_labels = val_data['features'], val_data['labels']\n",
        "test_features, test_labels = test_data['features'], test_data['labels']"
      ],
      "metadata": {
        "id": "Wv0_8VpbOd3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xb-fHd0d6p71",
        "outputId": "c6f8a755-18b2-44c7-d5f6-4e3b3578550d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(34799,)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of training examples: {len(train_features)}\")\n",
        "print(f\"Number of training labels: {len(train_labels)}\")\n",
        "print(f\"Number of validation examples: {len(val_features)}\")\n",
        "print(f\"Number of validtion labels: {len(val_labels)}\")\n",
        "print(f\"Number of test examples: {len(test_features)}\")\n",
        "print(f\"Number of test labels: {len(test_labels)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYwpmoaUPBgj",
        "outputId": "9c621e6f-bad3-4ca7-8f92-51b2251fa725"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 34799\n",
            "Number of training labels: 34799\n",
            "Number of validation examples: 4410\n",
            "Number of validtion labels: 4410\n",
            "Number of test examples: 12630\n",
            "Number of test labels: 12630\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_train_samples, *input_shape = train_features.shape\n",
        "num_classes = 43\n",
        "print(f\"Input shape:{input_shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elSUNSDEPExD",
        "outputId": "ed349eee-9a50-4b02-dc0b-f15acbb030ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape:[32, 32, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Pixel Range:{np.min(train_features), np.max(train_features)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFSDYPkuSAeU",
        "outputId": "2c8b901b-feae-4dac-eb10-ff4634a54e25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pixel Range:(0, 255)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices((train_features, train_labels)).shuffle(buffer_size=num_train_samples)\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((val_features, val_labels)).shuffle(buffer_size=val_features.shape[0])\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((test_features, test_labels))"
      ],
      "metadata": {
        "id": "U0Sgd_jrSuUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, l in train_ds.take(1):\n",
        "  print(l)\n",
        "  print(tf.one_hot(l, depth=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tddu1kOj9zO5",
        "outputId": "d7e5dcd7-80d2-4d4b-8fc2-a23dc9b67e3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(4, shape=(), dtype=uint8)\n",
            "tf.Tensor([0. 0. 0. 0. 1. 0. 0. 0. 0. 0.], shape=(10,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Method 1\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "augmentator = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "9vbT70tEUB9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "train_ds = train_ds.batch(BATCH_SIZE).cache().prefetch(tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.batch(BATCH_SIZE).cache().prefetch(tf.data.AUTOTUNE)\n",
        "test_ds = test_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "PS1Y_DR9fru0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Augmented image data\n",
        "\n",
        "ds_train_aug = augmentator.flow((train_features, train_labels), batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "i3Rjy1nZg8jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Architecture"
      ],
      "metadata": {
        "id": "g48DLsm-ifsx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Flatten, Dense\n",
        "from tensorflow.keras.layers import Rescaling"
      ],
      "metadata": {
        "id": "fzTbw1Eehf0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### No data augmentation"
      ],
      "metadata": {
        "id": "352kTVPczv1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Rescaling(scale=1./255, input_shape=input_shape),\n",
        "    Conv2D(32, (2, 2), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    Conv2D(32, (2, 2), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    Conv2D(64, (2, 2), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    Conv2D(64, (2, 2), padding=\"same\", activation=\"relu\"),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(512, activation=\"relu\"),\n",
        "    Dense(num_classes, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7iDKFgGi7K7",
        "outputId": "212e8c52-00c9-4af9-87fc-553bf7d45bd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rescaling (Rescaling)       (None, 32, 32, 3)         0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        416       \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 32, 32, 32)        128       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 16, 16, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 16, 16, 32)        4128      \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 16, 16, 32)        128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 8, 8, 32)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 8, 8, 64)          8256      \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 8, 8, 64)          256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 4, 4, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 4, 4, 64)          16448     \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 4, 4, 64)          256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 2, 2, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               131584    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 43)                22059     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 183659 (717.42 KB)\n",
            "Trainable params: 183275 (715.92 KB)\n",
            "Non-trainable params: 384 (1.50 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=losses.SparseCategoricalCrossentropy(),\n",
        "              optimizer=optimizers.Adam(learning_rate=0.001),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(train_ds,\n",
        "          validation_data=val_ds,\n",
        "          epochs=50,\n",
        "          callbacks=[tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join('.', model.name)+'.h5',\n",
        "                                                        monitor='val_accuracy',\n",
        "                                                        verbose=1,\n",
        "                                                        save_best_only=True\n",
        "                                                        )])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abNQN0nNkb-c",
        "outputId": "9793b024-7b2d-44a7-9fc5-d484808cc8f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "271/272 [============================>.] - ETA: 0s - loss: 0.0101 - accuracy: 0.9969\n",
            "Epoch 1: val_accuracy improved from -inf to 0.90658, saving model to ./sequential.h5\n",
            "272/272 [==============================] - 4s 6ms/step - loss: 0.0100 - accuracy: 0.9970 - val_loss: 0.7219 - val_accuracy: 0.9066\n",
            "Epoch 2/50\n",
            "270/272 [============================>.] - ETA: 0s - loss: 0.0089 - accuracy: 0.9972\n",
            "Epoch 2: val_accuracy did not improve from 0.90658\n",
            "272/272 [==============================] - 1s 5ms/step - loss: 0.0088 - accuracy: 0.9972 - val_loss: 0.8768 - val_accuracy: 0.8955\n",
            "Epoch 3/50\n",
            "265/272 [============================>.] - ETA: 0s - loss: 0.0076 - accuracy: 0.9976\n",
            "Epoch 3: val_accuracy did not improve from 0.90658\n",
            "272/272 [==============================] - 1s 5ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.7859 - val_accuracy: 0.8959\n",
            "Epoch 4/50\n",
            "262/272 [===========================>..] - ETA: 0s - loss: 0.0017 - accuracy: 0.9994\n",
            "Epoch 4: val_accuracy improved from 0.90658 to 0.91429, saving model to ./sequential.h5\n",
            "272/272 [==============================] - 1s 5ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.7169 - val_accuracy: 0.9143\n",
            "Epoch 5/50\n",
            "270/272 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9984\n",
            "Epoch 5: val_accuracy did not improve from 0.91429\n",
            "272/272 [==============================] - 1s 5ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.7786 - val_accuracy: 0.8950\n",
            "Epoch 6/50\n",
            "262/272 [===========================>..] - ETA: 0s - loss: 0.0179 - accuracy: 0.9950\n",
            "Epoch 6: val_accuracy did not improve from 0.91429\n",
            "272/272 [==============================] - 1s 5ms/step - loss: 0.0175 - accuracy: 0.9951 - val_loss: 1.0411 - val_accuracy: 0.8782\n",
            "Epoch 7/50\n",
            "263/272 [============================>.] - ETA: 0s - loss: 0.0080 - accuracy: 0.9975\n",
            "Epoch 7: val_accuracy did not improve from 0.91429\n",
            "272/272 [==============================] - 1s 5ms/step - loss: 0.0084 - accuracy: 0.9973 - val_loss: 0.7122 - val_accuracy: 0.8966\n",
            "Epoch 8/50\n",
            "269/272 [============================>.] - ETA: 0s - loss: 0.0085 - accuracy: 0.9977\n",
            "Epoch 8: val_accuracy did not improve from 0.91429\n",
            "272/272 [==============================] - 1s 5ms/step - loss: 0.0085 - accuracy: 0.9977 - val_loss: 1.0519 - val_accuracy: 0.8794\n",
            "Epoch 9/50\n",
            "264/272 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.9981\n",
            "Epoch 9: val_accuracy did not improve from 0.91429\n",
            "272/272 [==============================] - 1s 5ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.7306 - val_accuracy: 0.9045\n",
            "Epoch 10/50\n",
            "263/272 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9993\n",
            "Epoch 10: val_accuracy did not improve from 0.91429\n",
            "272/272 [==============================] - 1s 5ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.9637 - val_accuracy: 0.8864\n",
            "Epoch 11/50\n",
            "267/272 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9995\n",
            "Epoch 11: val_accuracy improved from 0.91429 to 0.91905, saving model to ./sequential.h5\n",
            "272/272 [==============================] - 1s 5ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.6708 - val_accuracy: 0.9190\n",
            "Epoch 12/50\n",
            "269/272 [============================>.] - ETA: 0s - loss: 2.0617e-04 - accuracy: 0.9999\n",
            "Epoch 12: val_accuracy did not improve from 0.91905\n",
            "272/272 [==============================] - 1s 5ms/step - loss: 2.0892e-04 - accuracy: 0.9999 - val_loss: 0.7382 - val_accuracy: 0.9150\n",
            "Epoch 13/50\n",
            "265/272 [============================>.] - ETA: 0s - loss: 1.4232e-04 - accuracy: 0.9999\n",
            "Epoch 13: val_accuracy improved from 0.91905 to 0.92109, saving model to ./sequential.h5\n",
            "272/272 [==============================] - 1s 5ms/step - loss: 1.4202e-04 - accuracy: 0.9999 - val_loss: 0.6730 - val_accuracy: 0.9211\n",
            "Epoch 14/50\n",
            "265/272 [============================>.] - ETA: 0s - loss: 2.6514e-05 - accuracy: 1.0000\n",
            "Epoch 14: val_accuracy improved from 0.92109 to 0.92381, saving model to ./sequential.h5\n",
            "272/272 [==============================] - 1s 5ms/step - loss: 2.6041e-05 - accuracy: 1.0000 - val_loss: 0.6933 - val_accuracy: 0.9238\n",
            "Epoch 15/50\n",
            "271/272 [============================>.] - ETA: 0s - loss: 6.7591e-06 - accuracy: 1.0000\n",
            "Epoch 15: val_accuracy improved from 0.92381 to 0.92426, saving model to ./sequential.h5\n",
            "272/272 [==============================] - 1s 5ms/step - loss: 6.7383e-06 - accuracy: 1.0000 - val_loss: 0.6922 - val_accuracy: 0.9243\n",
            "Epoch 16/50\n",
            "264/272 [============================>.] - ETA: 0s - loss: 5.3498e-06 - accuracy: 1.0000\n",
            "Epoch 16: val_accuracy improved from 0.92426 to 0.92562, saving model to ./sequential.h5\n",
            "272/272 [==============================] - 1s 5ms/step - loss: 5.3075e-06 - accuracy: 1.0000 - val_loss: 0.6905 - val_accuracy: 0.9256\n",
            "Epoch 17/50\n",
            "269/272 [============================>.] - ETA: 0s - loss: 4.4825e-06 - accuracy: 1.0000\n",
            "Epoch 17: val_accuracy improved from 0.92562 to 0.92585, saving model to ./sequential.h5\n",
            "272/272 [==============================] - 1s 5ms/step - loss: 4.4482e-06 - accuracy: 1.0000 - val_loss: 0.6894 - val_accuracy: 0.9259\n",
            "Epoch 18/50\n",
            "267/272 [============================>.] - ETA: 0s - loss: 3.8654e-06 - accuracy: 1.0000\n",
            "Epoch 18: val_accuracy did not improve from 0.92585\n",
            "272/272 [==============================] - 1s 5ms/step - loss: 3.8231e-06 - accuracy: 1.0000 - val_loss: 0.6885 - val_accuracy: 0.9247\n",
            "Epoch 19/50\n",
            "266/272 [============================>.] - ETA: 0s - loss: 3.3507e-06 - accuracy: 1.0000\n",
            "Epoch 19: val_accuracy did not improve from 0.92585\n",
            "272/272 [==============================] - 1s 5ms/step - loss: 3.3365e-06 - accuracy: 1.0000 - val_loss: 0.6878 - val_accuracy: 0.9247\n",
            "Epoch 20/50\n",
            "269/272 [============================>.] - ETA: 0s - loss: 2.9604e-06 - accuracy: 1.0000\n",
            "Epoch 20: val_accuracy did not improve from 0.92585\n",
            "272/272 [==============================] - 1s 5ms/step - loss: 2.9398e-06 - accuracy: 1.0000 - val_loss: 0.6873 - val_accuracy: 0.9247\n",
            "Epoch 21/50\n",
            "262/272 [===========================>..] - ETA: 0s - loss: 2.5976e-06 - accuracy: 1.0000\n",
            "Epoch 21: val_accuracy did not improve from 0.92585\n",
            "272/272 [==============================] - 1s 5ms/step - loss: 2.6084e-06 - accuracy: 1.0000 - val_loss: 0.6870 - val_accuracy: 0.9249\n",
            "Epoch 22/50\n",
            "264/272 [============================>.] - ETA: 0s - loss: 2.3359e-06 - accuracy: 1.0000\n",
            "Epoch 22: val_accuracy did not improve from 0.92585\n",
            "272/272 [==============================] - 1s 5ms/step - loss: 2.3258e-06 - accuracy: 1.0000 - val_loss: 0.6870 - val_accuracy: 0.9249\n",
            "Epoch 23/50\n",
            "272/272 [==============================] - ETA: 0s - loss: 2.0812e-06 - accuracy: 1.0000\n",
            "Epoch 23: val_accuracy did not improve from 0.92585\n",
            "272/272 [==============================] - 1s 5ms/step - loss: 2.0812e-06 - accuracy: 1.0000 - val_loss: 0.6870 - val_accuracy: 0.9252\n",
            "Epoch 24/50\n",
            "264/272 [============================>.] - ETA: 0s - loss: 1.8722e-06 - accuracy: 1.0000\n",
            "Epoch 24: val_accuracy did not improve from 0.92585\n",
            "272/272 [==============================] - 1s 5ms/step - loss: 1.8666e-06 - accuracy: 1.0000 - val_loss: 0.6872 - val_accuracy: 0.9252\n",
            "Epoch 25/50\n",
            "264/272 [============================>.] - ETA: 0s - loss: 1.6804e-06 - accuracy: 1.0000\n",
            "Epoch 25: val_accuracy did not improve from 0.92585\n",
            "272/272 [==============================] - 1s 5ms/step - loss: 1.6764e-06 - accuracy: 1.0000 - val_loss: 0.6874 - val_accuracy: 0.9254\n",
            "Epoch 26/50\n",
            "272/272 [==============================] - ETA: 0s - loss: 1.5060e-06 - accuracy: 1.0000\n",
            "Epoch 26: val_accuracy did not improve from 0.92585\n",
            "272/272 [==============================] - 2s 6ms/step - loss: 1.5060e-06 - accuracy: 1.0000 - val_loss: 0.6878 - val_accuracy: 0.9252\n",
            "Epoch 27/50\n",
            "262/272 [===========================>..] - ETA: 0s - loss: 1.3444e-06 - accuracy: 1.0000\n",
            "Epoch 27: val_accuracy did not improve from 0.92585\n",
            "272/272 [==============================] - 1s 5ms/step - loss: 1.3541e-06 - accuracy: 1.0000 - val_loss: 0.6882 - val_accuracy: 0.9252\n",
            "Epoch 28/50\n",
            "272/272 [==============================] - ETA: 0s - loss: 1.2173e-06 - accuracy: 1.0000\n",
            "Epoch 28: val_accuracy did not improve from 0.92585\n",
            "272/272 [==============================] - 1s 5ms/step - loss: 1.2173e-06 - accuracy: 1.0000 - val_loss: 0.6887 - val_accuracy: 0.9254\n",
            "Epoch 29/50\n",
            "265/272 [============================>.] - ETA: 0s - loss: 1.0985e-06 - accuracy: 1.0000\n",
            "Epoch 29: val_accuracy did not improve from 0.92585\n",
            "272/272 [==============================] - 1s 5ms/step - loss: 1.0947e-06 - accuracy: 1.0000 - val_loss: 0.6892 - val_accuracy: 0.9256\n",
            "Epoch 30/50\n",
            "263/272 [============================>.] - ETA: 0s - loss: 9.8673e-07 - accuracy: 1.0000\n",
            "Epoch 30: val_accuracy improved from 0.92585 to 0.92630, saving model to ./sequential.h5\n",
            "272/272 [==============================] - 1s 5ms/step - loss: 9.8381e-07 - accuracy: 1.0000 - val_loss: 0.6896 - val_accuracy: 0.9263\n",
            "Epoch 31/50\n",
            "271/272 [============================>.] - ETA: 0s - loss: 8.8616e-07 - accuracy: 1.0000\n",
            "Epoch 31: val_accuracy improved from 0.92630 to 0.92653, saving model to ./sequential.h5\n",
            "272/272 [==============================] - 1s 5ms/step - loss: 8.8373e-07 - accuracy: 1.0000 - val_loss: 0.6902 - val_accuracy: 0.9265\n",
            "Epoch 32/50\n",
            "265/272 [============================>.] - ETA: 0s - loss: 7.9550e-07 - accuracy: 1.0000\n",
            "Epoch 32: val_accuracy did not improve from 0.92653\n",
            "272/272 [==============================] - 1s 5ms/step - loss: 7.9327e-07 - accuracy: 1.0000 - val_loss: 0.6908 - val_accuracy: 0.9263\n",
            "Epoch 33/50\n",
            "264/272 [============================>.] - ETA: 0s - loss: 7.1169e-07 - accuracy: 1.0000\n",
            "Epoch 33: val_accuracy improved from 0.92653 to 0.92676, saving model to ./sequential.h5\n",
            "272/272 [==============================] - 1s 5ms/step - loss: 7.1210e-07 - accuracy: 1.0000 - val_loss: 0.6916 - val_accuracy: 0.9268\n",
            "Epoch 34/50\n",
            "271/272 [============================>.] - ETA: 0s - loss: 6.4040e-07 - accuracy: 1.0000\n",
            "Epoch 34: val_accuracy did not improve from 0.92676\n",
            "272/272 [==============================] - 2s 6ms/step - loss: 6.3869e-07 - accuracy: 1.0000 - val_loss: 0.6925 - val_accuracy: 0.9265\n",
            "Epoch 35/50\n",
            "268/272 [============================>.] - ETA: 0s - loss: 5.7594e-07 - accuracy: 1.0000\n",
            "Epoch 35: val_accuracy did not improve from 0.92676\n",
            "272/272 [==============================] - 1s 5ms/step - loss: 5.7260e-07 - accuracy: 1.0000 - val_loss: 0.6932 - val_accuracy: 0.9265\n",
            "Epoch 36/50\n",
            "264/272 [============================>.] - ETA: 0s - loss: 5.1231e-07 - accuracy: 1.0000\n",
            "Epoch 36: val_accuracy did not improve from 0.92676\n",
            "272/272 [==============================] - 1s 5ms/step - loss: 5.1279e-07 - accuracy: 1.0000 - val_loss: 0.6941 - val_accuracy: 0.9268\n",
            "Epoch 37/50\n",
            "264/272 [============================>.] - ETA: 0s - loss: 4.5803e-07 - accuracy: 1.0000\n",
            "Epoch 37: val_accuracy did not improve from 0.92676\n",
            "272/272 [==============================] - 1s 5ms/step - loss: 4.5846e-07 - accuracy: 1.0000 - val_loss: 0.6948 - val_accuracy: 0.9268\n",
            "Epoch 38/50\n",
            "266/272 [============================>.] - ETA: 0s - loss: 4.1015e-07 - accuracy: 1.0000\n",
            "Epoch 38: val_accuracy improved from 0.92676 to 0.92721, saving model to ./sequential.h5\n",
            "272/272 [==============================] - 1s 5ms/step - loss: 4.0930e-07 - accuracy: 1.0000 - val_loss: 0.6957 - val_accuracy: 0.9272\n",
            "Epoch 39/50\n",
            "265/272 [============================>.] - ETA: 0s - loss: 3.6615e-07 - accuracy: 1.0000\n",
            "Epoch 39: val_accuracy did not improve from 0.92721\n",
            "272/272 [==============================] - 1s 5ms/step - loss: 3.6540e-07 - accuracy: 1.0000 - val_loss: 0.6968 - val_accuracy: 0.9270\n",
            "Epoch 40/50\n",
            "262/272 [===========================>..] - ETA: 0s - loss: 3.2372e-07 - accuracy: 1.0000\n",
            "Epoch 40: val_accuracy did not improve from 0.92721\n",
            "272/272 [==============================] - 1s 5ms/step - loss: 3.2591e-07 - accuracy: 1.0000 - val_loss: 0.6979 - val_accuracy: 0.9270\n",
            "Epoch 41/50\n",
            "270/272 [============================>.] - ETA: 0s - loss: 2.9198e-07 - accuracy: 1.0000\n",
            "Epoch 41: val_accuracy did not improve from 0.92721\n",
            "272/272 [==============================] - 1s 5ms/step - loss: 2.9032e-07 - accuracy: 1.0000 - val_loss: 0.6990 - val_accuracy: 0.9270\n",
            "Epoch 42/50\n",
            "271/272 [============================>.] - ETA: 0s - loss: 2.5909e-07 - accuracy: 1.0000\n",
            "Epoch 42: val_accuracy improved from 0.92721 to 0.92744, saving model to ./sequential.h5\n",
            "272/272 [==============================] - 2s 6ms/step - loss: 2.5842e-07 - accuracy: 1.0000 - val_loss: 0.7003 - val_accuracy: 0.9274\n",
            "Epoch 43/50\n",
            "265/272 [============================>.] - ETA: 0s - loss: 2.3024e-07 - accuracy: 1.0000\n",
            "Epoch 43: val_accuracy improved from 0.92744 to 0.92766, saving model to ./sequential.h5\n",
            "272/272 [==============================] - 1s 5ms/step - loss: 2.2984e-07 - accuracy: 1.0000 - val_loss: 0.7016 - val_accuracy: 0.9277\n",
            "Epoch 44/50\n",
            "272/272 [==============================] - ETA: 0s - loss: 2.0439e-07 - accuracy: 1.0000\n",
            "Epoch 44: val_accuracy did not improve from 0.92766\n",
            "272/272 [==============================] - 1s 5ms/step - loss: 2.0439e-07 - accuracy: 1.0000 - val_loss: 0.7029 - val_accuracy: 0.9274\n",
            "Epoch 45/50\n",
            "265/272 [============================>.] - ETA: 0s - loss: 1.8205e-07 - accuracy: 1.0000\n",
            "Epoch 45: val_accuracy did not improve from 0.92766\n",
            "272/272 [==============================] - 1s 5ms/step - loss: 1.8174e-07 - accuracy: 1.0000 - val_loss: 0.7042 - val_accuracy: 0.9274\n",
            "Epoch 46/50\n",
            "264/272 [============================>.] - ETA: 0s - loss: 1.6125e-07 - accuracy: 1.0000\n",
            "Epoch 46: val_accuracy did not improve from 0.92766\n",
            "272/272 [==============================] - 1s 5ms/step - loss: 1.6142e-07 - accuracy: 1.0000 - val_loss: 0.7057 - val_accuracy: 0.9277\n",
            "Epoch 47/50\n",
            "269/272 [============================>.] - ETA: 0s - loss: 1.4388e-07 - accuracy: 1.0000\n",
            "Epoch 47: val_accuracy improved from 0.92766 to 0.92789, saving model to ./sequential.h5\n",
            "272/272 [==============================] - 1s 5ms/step - loss: 1.4321e-07 - accuracy: 1.0000 - val_loss: 0.7072 - val_accuracy: 0.9279\n",
            "Epoch 48/50\n",
            "270/272 [============================>.] - ETA: 0s - loss: 1.2759e-07 - accuracy: 1.0000\n",
            "Epoch 48: val_accuracy improved from 0.92789 to 0.92812, saving model to ./sequential.h5\n",
            "272/272 [==============================] - 1s 5ms/step - loss: 1.2687e-07 - accuracy: 1.0000 - val_loss: 0.7089 - val_accuracy: 0.9281\n",
            "Epoch 49/50\n",
            "264/272 [============================>.] - ETA: 0s - loss: 1.1229e-07 - accuracy: 1.0000\n",
            "Epoch 49: val_accuracy improved from 0.92812 to 0.92834, saving model to ./sequential.h5\n",
            "272/272 [==============================] - 1s 5ms/step - loss: 1.1237e-07 - accuracy: 1.0000 - val_loss: 0.7106 - val_accuracy: 0.9283\n",
            "Epoch 50/50\n",
            "265/272 [============================>.] - ETA: 0s - loss: 9.9753e-08 - accuracy: 1.0000\n",
            "Epoch 50: val_accuracy improved from 0.92834 to 0.92880, saving model to ./sequential.h5\n",
            "272/272 [==============================] - 1s 5ms/step - loss: 9.9536e-08 - accuracy: 1.0000 - val_loss: 0.7122 - val_accuracy: 0.9288\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c7d8e882d70>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r classify_traffic_signs.zip sequential.h5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDpedyUNyYk_",
        "outputId": "e415499f-e120-402c-9978-aece25662be1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: sequential.h5 (deflated 11%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Augmented Data"
      ],
      "metadata": {
        "id": "9j6HNk6az0IJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=losses.SparseCategoricalCrossentropy(),\n",
        "              optimizer=optimizers.RMSprop(),\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(ds_train_aug,\n",
        "          validation_data=(val_features, val_labels),\n",
        "          epochs=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQQZSUtLzzSw",
        "outputId": "332323c0-d2ff-4e78-bb9d-26bdf389a0e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "272/272 [==============================] - 19s 64ms/step - loss: 0.7264 - accuracy: 0.8202 - val_loss: 0.6867 - val_accuracy: 0.8728\n",
            "Epoch 2/30\n",
            "272/272 [==============================] - 17s 62ms/step - loss: 0.2904 - accuracy: 0.9013 - val_loss: 0.7952 - val_accuracy: 0.8574\n",
            "Epoch 3/30\n",
            "272/272 [==============================] - 17s 64ms/step - loss: 0.2257 - accuracy: 0.9227 - val_loss: 0.6866 - val_accuracy: 0.8662\n",
            "Epoch 4/30\n",
            "272/272 [==============================] - 17s 63ms/step - loss: 0.1972 - accuracy: 0.9324 - val_loss: 0.7950 - val_accuracy: 0.8571\n",
            "Epoch 5/30\n",
            "272/272 [==============================] - 18s 64ms/step - loss: 0.1629 - accuracy: 0.9447 - val_loss: 0.9114 - val_accuracy: 0.8517\n",
            "Epoch 6/30\n",
            "272/272 [==============================] - 17s 63ms/step - loss: 0.1500 - accuracy: 0.9487 - val_loss: 0.8232 - val_accuracy: 0.8476\n",
            "Epoch 7/30\n",
            "272/272 [==============================] - 17s 63ms/step - loss: 0.1469 - accuracy: 0.9498 - val_loss: 0.8201 - val_accuracy: 0.8542\n",
            "Epoch 8/30\n",
            "272/272 [==============================] - 17s 61ms/step - loss: 0.1363 - accuracy: 0.9538 - val_loss: 0.9302 - val_accuracy: 0.8440\n",
            "Epoch 9/30\n",
            "272/272 [==============================] - 17s 62ms/step - loss: 0.1261 - accuracy: 0.9580 - val_loss: 0.9360 - val_accuracy: 0.8324\n",
            "Epoch 10/30\n",
            "272/272 [==============================] - 17s 62ms/step - loss: 0.1190 - accuracy: 0.9604 - val_loss: 0.8954 - val_accuracy: 0.8540\n",
            "Epoch 11/30\n",
            "272/272 [==============================] - 17s 62ms/step - loss: 0.1146 - accuracy: 0.9615 - val_loss: 1.0648 - val_accuracy: 0.8351\n",
            "Epoch 12/30\n",
            "272/272 [==============================] - 17s 63ms/step - loss: 0.1102 - accuracy: 0.9633 - val_loss: 0.9460 - val_accuracy: 0.8624\n",
            "Epoch 13/30\n",
            "272/272 [==============================] - 17s 62ms/step - loss: 0.1043 - accuracy: 0.9640 - val_loss: 1.0657 - val_accuracy: 0.8431\n",
            "Epoch 14/30\n",
            "272/272 [==============================] - 17s 61ms/step - loss: 0.1004 - accuracy: 0.9663 - val_loss: 0.9942 - val_accuracy: 0.8488\n",
            "Epoch 15/30\n",
            "272/272 [==============================] - 17s 62ms/step - loss: 0.0947 - accuracy: 0.9685 - val_loss: 1.0765 - val_accuracy: 0.8490\n",
            "Epoch 16/30\n",
            "272/272 [==============================] - 17s 61ms/step - loss: 0.0931 - accuracy: 0.9696 - val_loss: 1.1295 - val_accuracy: 0.8265\n",
            "Epoch 17/30\n",
            "272/272 [==============================] - 16s 60ms/step - loss: 0.0876 - accuracy: 0.9699 - val_loss: 1.0112 - val_accuracy: 0.8379\n",
            "Epoch 18/30\n",
            "272/272 [==============================] - 17s 61ms/step - loss: 0.0895 - accuracy: 0.9707 - val_loss: 1.1367 - val_accuracy: 0.8340\n",
            "Epoch 19/30\n",
            "272/272 [==============================] - 17s 61ms/step - loss: 0.0861 - accuracy: 0.9695 - val_loss: 1.2183 - val_accuracy: 0.8317\n",
            "Epoch 20/30\n",
            "272/272 [==============================] - 17s 61ms/step - loss: 0.0804 - accuracy: 0.9729 - val_loss: 0.9592 - val_accuracy: 0.8499\n",
            "Epoch 21/30\n",
            "272/272 [==============================] - 17s 62ms/step - loss: 0.0773 - accuracy: 0.9743 - val_loss: 1.0860 - val_accuracy: 0.8456\n",
            "Epoch 22/30\n",
            "272/272 [==============================] - 17s 61ms/step - loss: 0.0763 - accuracy: 0.9748 - val_loss: 1.0836 - val_accuracy: 0.8395\n",
            "Epoch 23/30\n",
            "272/272 [==============================] - 16s 60ms/step - loss: 0.0738 - accuracy: 0.9758 - val_loss: 1.3286 - val_accuracy: 0.8132\n",
            "Epoch 24/30\n",
            "272/272 [==============================] - 17s 61ms/step - loss: 0.0749 - accuracy: 0.9760 - val_loss: 1.0259 - val_accuracy: 0.8397\n",
            "Epoch 25/30\n",
            "272/272 [==============================] - 17s 61ms/step - loss: 0.0695 - accuracy: 0.9767 - val_loss: 1.1591 - val_accuracy: 0.8354\n",
            "Epoch 26/30\n",
            "272/272 [==============================] - 16s 61ms/step - loss: 0.0714 - accuracy: 0.9764 - val_loss: 1.1346 - val_accuracy: 0.8469\n",
            "Epoch 27/30\n",
            "272/272 [==============================] - 17s 61ms/step - loss: 0.0669 - accuracy: 0.9780 - val_loss: 1.1313 - val_accuracy: 0.8320\n",
            "Epoch 28/30\n",
            "272/272 [==============================] - 16s 60ms/step - loss: 0.0659 - accuracy: 0.9778 - val_loss: 1.3039 - val_accuracy: 0.8354\n",
            "Epoch 29/30\n",
            "272/272 [==============================] - 16s 61ms/step - loss: 0.0649 - accuracy: 0.9786 - val_loss: 1.1718 - val_accuracy: 0.8315\n",
            "Epoch 30/30\n",
            "272/272 [==============================] - 17s 61ms/step - loss: 0.0578 - accuracy: 0.9810 - val_loss: 1.0778 - val_accuracy: 0.8524\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b00d2109c30>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    }
  ]
}